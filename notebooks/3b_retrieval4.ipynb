{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human coding\n",
    "\n",
    "In this notebook, we will work with the following aspects of human coding:\n",
    "\n",
    "1. Revisiting our identifier example \n",
    "1. Human coding design\n",
    "1. Heuristics\n",
    "1. Cartesian joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifier example\n",
    "\n",
    "Returning to our identifier example from the planning segment, we can look through some elements of the design of a coding spreadsheet.\n",
    "\n",
    "Note: I removed one year from each firm for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding = pd.DataFrame([\n",
    "    {'name': 'Apple',\n",
    "     'year': '2018'},\n",
    "    {'name': 'Apple',\n",
    "     'year': '2019'},\n",
    "    {'name': 'Microsoft',\n",
    "     'year': '2018'},\n",
    "    {'name': 'Microsoft',\n",
    "     'year': '2019'},\n",
    "    {'name': 'Berkshire Hathaway',\n",
    "     'year': '2018'},\n",
    "    {'name': 'Berkshire Hathaway',\n",
    "     'year': '2019'}\n",
    "])\n",
    "\n",
    "coding.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get unique values of a column with the unique method.\n",
    "coding['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can make a new dataframe with those unique values.\n",
    "code_table = pd.DataFrame(coding['name'].unique())\n",
    "code_table = code_table.rename(columns={0: 'name'})\n",
    "code_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we can populate new columns for use in coding.\n",
    "for new_col in ['gvkey', 'source', 'coder', 'flag', 'notes']:\n",
    "    code_table[new_col] = ''\n",
    "code_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human coding design\n",
    "\n",
    "When we design coding processes for humans, there are a few important things that we need to manage and balance.\n",
    "\n",
    "1. Cost/time spent\n",
    "1. Future use and versatility\n",
    "1. Consistency across time and coders\n",
    "1. Cleanness of data\n",
    "1. Identification of errors\n",
    "\n",
    "\n",
    "There are a few practices that I suggest, which we can see embedded in the example above.\n",
    "\n",
    "1. **Minimize what you present to coders.** This table has a lot less than a typical dataset, because we only want to provide what is needed to do the work. While we don't have to be extremely strict about this (i.e. including a column for meaningful context but not direct use is sometimes helpful), everything you add has a cost in time.\n",
    "1. **Communicate a benchmark for completing work.** Coders are sometimes less than particularly diligent (and it's fair to say that this is often tedious work). I have found that communicating a specific benchmark, even a generous one (I tend to multiply my average over a couple dozen observations by 2.0), improves output. You can use things like file creation times or Dropbox revisions (depending on the design) to compute the time as a way of measuring compliance.\n",
    "1. **Capture information that helps improve the process.** It may not be strictly necessary to capture the source here, but it may be useful to have. For example, if we had a cascading design, we might find that some sources are not helpful enough to include going forward.\n",
    "1. **Provide explicit instructions.** Instructions help the same person perform similarly over time, and they help us keep multiple coders in sync. They can also be helpful to show to reviewers to give face validity to the rigor of the management of the coding protocol.\n",
    "1. **Give coders a mechanism to raise issues and capture the unexpected.** Here, I use a flag column and a notes column. The idea is that a flag tells me to look at it, and notes capture something unexpected. I advise coders that using this is rare, but it's there to surface things that they notice. Without this, you sometimes get responses like (for example, for gvkey) \"001234 or 056789.\" This will read in as the wrong type, and it won't merge properly (even if one of them is correct). By giving them a mechanism (and instructions) to communicate, they can choose the better of the two, flag it, and make a note.\n",
    "1. **Establish a review process to detect errors.** I typically have two forms of review. First, when onboarding a new coder, we have them do a short list of coding tasks (from the real data) that we use for every new coder. We use this to detect errors in process or conscientiousness early and correct them, and it's common to have issues (around 50 percent of new coders have at least one issue, in my experience). Using the same list means that we know those particular issues. Second, for more nuanced/complex projects, we write instructions for reviewing the work that is submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristics\n",
    "\n",
    "Sometimes, we have an imperfect way of coding a variable that works a reasonable amount of the time.\n",
    "The idea here is that we can pre-populate those heuristic values, and we ask coders to check them, leave them if they are correct, and correct them if not.\n",
    "\n",
    "It's worth noting that this necessarily increases the nuance and complexity of a coding task.\n",
    "On the other hand, if the coders are not unduly anchored by the heuristic, it can create a substantial time savings by reducing data entry.\n",
    "These issues make me more likely to use this technique with coders who we know to do good work, PhD students, and other co-authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_nyt = pd.read_csv('../data/msft_nyt.csv')\n",
    "msft_nyt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_coding = msft_nyt[['_id', 'headline.main']].copy()\n",
    "msft_coding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_col in ['is_significant', 'coder', 'flag', 'notes']:\n",
    "    msft_coding[new_col] = ''\n",
    "msft_coding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhaps we think the word billion in the headline makes something\n",
    "# likely to be significant.\n",
    "def code_significant(text):\n",
    "    if 'billion' in text.lower():\n",
    "        return '1'\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_coding['is_significant'] = msft_coding['headline.main'].apply(code_significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_coding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, I write a simple function that is designed to operate on one string, and I use the `apply` method on the `headline.main` column to apply that function to each row.\n",
    "Another common pattern is to merge in the values that may work, and use the coding process to check them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartesian joins\n",
    "\n",
    "A [Cartesian product](https://en.wikipedia.org/wiki/Join_\\(SQL\\)#Cross_join) (also called a \"cross join\") is a combination of each row in one set of data with each row in another set of data.\n",
    "As you can imagine, the length of the new data is $n \\times m$, which gets very large as $n$ and $m$ increase.\n",
    "However, when we can use small groups, these products become manageable.\n",
    "\n",
    "## Conference call example\n",
    "\n",
    "Imagine that we have conference call data consisting of a list of participants and then a transcript where we can isolate the names, but they don't quite match the participant list.\n",
    "These are reasonably short-length lists, so we can use a Cartesian product for coding.\n",
    "The idea is that we will have all of the combinations, and we expect there to be a proper match on both sides (not strictly required, but it helps), so we can produce all of the combinations and have a coder mark the proper one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = pd.DataFrame([\n",
    "    {'name': 'Abbie Executive (CEO)'},\n",
    "    {'name': 'Bruce Executive (CFO)'},\n",
    "    {'name': 'Charles Analyst (Firm1)'},\n",
    "    {'name': 'Bella Analyst (Firm2)'}\n",
    "])\n",
    "participants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = pd.DataFrame([\n",
    "    {'name': 'Operator'},\n",
    "    {'name': 'Abbie E.'},\n",
    "    {'name': 'Bruce E.'},\n",
    "    {'name': 'Charles A.'},\n",
    "    {'name': 'Bella A.'}\n",
    "])\n",
    "speaker.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_coding = participants.merge(speaker, how='cross')\n",
    "call_coding['correct'] = ''\n",
    "call_coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we now have 20 rows from lists of five and four (i.e. `5 * 4`).\n",
    "That is a big expansion in length, but these are fast to code.\n",
    "If you look through the rows, you'll notice that you can ascertain matches very quickly, and most rows do not match.\n",
    "Using this technique, we've seen coders reliably exceed 40 rows per minute.\n",
    "It also has the benefit of preventing much entry, except the for `1`s entered for matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mockup = [1, 7, 13, 19]\n",
    "call_coding.loc[mockup, 'correct'] = 1\n",
    "call_coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_coding[call_coding['correct'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last form with the correct rows filtered becomes our lookup table to match these two forms of names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A: Human coding\n",
    "\n",
    "At the end, we will chat as one big group about human coding experiences and issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
